import re
import logging
import os
import pickle
from typing import List, Optional
import pandas as pd
import numpy as np
import jieba
import torch
import time
import asyncio

from fastapi import FastAPI, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from rapidfuzz import process, fuzz

try:
    from sentence_transformers import SentenceTransformer
    HAVE_ST = True
except Exception:
    HAVE_ST = False

# ================= Êó•ÂøóÈÖçÁΩÆ =================
logging.basicConfig(level=logging.INFO, format="%(asctime)s | %(levelname)s | %(message)s")
logger = logging.getLogger("formula-api")

# ================= FastAPI ÂàùÂßãÂåñ =================
app = FastAPI(title="Formula Query API - Jieba + Semantic (weighted hybrid)")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"]
)

# ================= ÂÖ®Â±ÄË∑ØÂæÑÈÖçÁΩÆ =================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.abspath(os.path.join(BASE_DIR, ".."))

DATA_DIR = os.path.join(PROJECT_ROOT, "data")
MODELS_DIR = os.path.join(PROJECT_ROOT, "models", "sbert_offline_models")

EMBEDDING_CACHE_PATH = os.path.join(DATA_DIR, "formula_embeddings.pkl")
FORMULA_CSV_PATH = os.path.join(DATA_DIR, "FORMULAINFO_202503121558.csv")

# ---- Á¶ªÁ∫øÊ®°Âûã‰ºòÂÖàË∑ØÂæÑ ----
OFFLINE_MODEL_PATH = os.path.join(MODELS_DIR, "86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d")

# ---- Âú®Á∫øÊ®°ÂûãÂ§áÁî® ----
EMBEDDING_MODEL_NAME = "paraphrase-multilingual-MiniLM-L12-v2"

# ÁéØÂ¢ÉÂèòÈáèËÆæÂ§áÊéßÂà∂
ENV_EMBEDDING_DEVICE = os.environ.get("EMBEDDING_DEVICE", "").lower()

# ÊñáÊú¨ÊùÉÈáçËßÑÂàô
TEXT_SCORE_WEIGHT_MAP = {
    "ÂÆûÁª©": 0.08,
    "Êä•Âá∫": 0.01,
    "ËÆ°Âàí": -0.01,
    "Á¥ØËÆ°": -0.02,
}
ENABLE_TEXT_SCORE_WEIGHT = True

# ================= ÂÖ®Â±ÄÂèòÈáè =================
df: Optional[pd.DataFrame] = None
_formulanames_raw: List[str] = []
_formulanames_clean: List[str] = []
_formulanames_tokens: List[str] = []
_embeddings: Optional[np.ndarray] = None
_embedding_model = None
_initialized = False  # ‚úÖ Èò≤Ê≠¢ÈáçÂ§çÂàùÂßãÂåñ


# ===========================================================
# Â∑•ÂÖ∑ÂáΩÊï∞
# ===========================================================
def normalize_text(s: str) -> str:
    if s is None:
        return ""
    s = str(s).strip().strip('"').strip("'")
    s = s.replace("#", " ")
    s = re.sub(r"[^\w\u4e00-\u9fff]+", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s


def tokens_by_jieba(s: str) -> str:
    if not s:
        return ""
    segs = jieba.cut(s, cut_all=False)
    return " ".join([t for t in segs if t.strip()])


def l2_normalize_matrix(mat: np.ndarray) -> np.ndarray:
    norms = np.linalg.norm(mat, axis=1, keepdims=True)
    norms[norms == 0] = 1.0
    return mat / norms


def select_embedding_device() -> str:
    """Ëá™Âä®ÈÄâÊã©ËÆæÂ§áÔºà‰ºòÂÖàÁéØÂ¢ÉÂèòÈáèÔºâ"""
    device = "cpu"
    if ENV_EMBEDDING_DEVICE in ["cuda", "mps", "cpu"]:
        device = ENV_EMBEDDING_DEVICE
        logger.info(f"Using embedding device from environment: {device}")
    else:
        if torch.cuda.is_available():
            device = "cuda"
        elif hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
            device = "mps"
        logger.info(f"Auto-selected embedding device: {device}")
    return device


def apply_text_weights(formula_name: str, base_score: float) -> float:
    if not ENABLE_TEXT_SCORE_WEIGHT or base_score <= 0:
        return base_score
    weighted_score = base_score
    for key, w in TEXT_SCORE_WEIGHT_MAP.items():
        if key in formula_name:
            weighted_score *= (1 + w)
    return weighted_score


# ===========================================================
# ÂàùÂßãÂåñÂáΩÊï∞ÔºàÊ†∏ÂøÉÊîπÂä®Ôºâ
# ===========================================================
def initialize():
    """ÂàùÂßãÂåñÂÖ¨ÂºèÊï∞ÊçÆ‰∏éÂµåÂÖ•ÔºåÂè™ÊâßË°å‰∏ÄÊ¨°"""
    global df, _formulanames_raw, _formulanames_clean, _formulanames_tokens
    global _embedding_model, _embeddings, HAVE_ST, _initialized

    # ‚úÖ ÈÅøÂÖçÈáçÂ§çÂä†ËΩΩÔºà‰ªé main.py ÂØºÂÖ•‰∏ç‰ºöÊâßË°åÁ¨¨‰∫åÊ¨°Ôºâ
    if _initialized:
        logger.info("‚úÖ formula_api Â∑≤ÂàùÂßãÂåñÔºåË∑≥ËøáÈáçÂ§çÂä†ËΩΩ„ÄÇ")
        return

    start_time = time.time()
    logger.info("üîÑ Ê≠£Âú®ÂàùÂßãÂåñÂÖ¨ÂºèÊï∞ÊçÆÔºàfull loadÔºâ...")

    # ---- Âä†ËΩΩ CSV ----
    if not os.path.exists(FORMULA_CSV_PATH):
        raise RuntimeError(f"‚ö†Ô∏è Êâæ‰∏çÂà∞ÂÖ¨ÂºèÊï∞ÊçÆÊñá‰ª∂: {os.path.abspath(FORMULA_CSV_PATH)}")

    try:
        df = pd.read_csv(FORMULA_CSV_PATH, dtype=str, quoting=3, engine="python", on_bad_lines="skip")
        df.columns = [c.strip().replace('"', '') for c in df.columns]
        if not {"FORMULAID", "FORMULANAME"}.issubset(df.columns):
            raise RuntimeError(f"CSV Áº∫Â∞ëÂøÖË¶ÅÂàó: {list(df.columns)}")
        df = df[["FORMULAID", "FORMULANAME"]].fillna("")
        _formulanames_raw = df["FORMULANAME"].astype(str).tolist()
        _formulanames_clean = [normalize_text(s) for s in _formulanames_raw]
        _formulanames_tokens = [tokens_by_jieba(s) for s in _formulanames_clean]
        _ = list(jieba.cut("ÊµãËØï"))  # Ëß¶Âèë jieba ÂàùÂßãÂåñ
        logger.info(f"‚úÖ Loaded {len(df)} formulas. Tokenization ready.")
    except Exception as e:
        logger.exception("‚ùå Failed to load CSV")
        raise RuntimeError(f"Failed to load CSV: {e}")

    # ---- Â∞ùËØïÂä†ËΩΩÂµåÂÖ•Ê®°Âûã ----
    if HAVE_ST:
        device = select_embedding_device()
        try:
            # ‚úÖ ‰ºòÂÖàÂä†ËΩΩÊú¨Âú∞Ê®°Âûã
            if os.path.exists(OFFLINE_MODEL_PATH):
                logger.info(f"üß© Â∞ùËØïÂä†ËΩΩÊú¨Âú∞Ê®°Âûã: {OFFLINE_MODEL_PATH}")
                _embedding_model = SentenceTransformer(OFFLINE_MODEL_PATH, device=device)
                logger.info("‚úÖ Â∑≤ÊàêÂäüÂä†ËΩΩÁ¶ªÁ∫øÊ®°Âûã„ÄÇ")
            else:
                logger.warning("‚ö†Ô∏è Á¶ªÁ∫øÊ®°ÂûãÊú™ÊâæÂà∞Ôºå‰ΩøÁî®ÈªòËÆ§Âú®Á∫øÊ®°Âûã„ÄÇ")
                _embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME, device=device)
                logger.info("‚úÖ Â∑≤Âä†ËΩΩÂú®Á∫øÊ®°Âûã„ÄÇ")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Êú¨Âú∞Ê®°ÂûãÂä†ËΩΩÂ§±Ë¥•ÔºåÂõûÈÄÄÂà∞Âú®Á∫øÊ®°Âûã„ÄÇÈîôËØØ: {e}")
            _embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME, device=device)
            logger.info("‚úÖ Â∑≤Âä†ËΩΩÂú®Á∫øÊ®°Âûã„ÄÇ")

        # ---- Âä†ËΩΩÊàñÁîüÊàêÂµåÂÖ•ÁºìÂ≠ò ----
        if os.path.exists(EMBEDDING_CACHE_PATH):
            with open(EMBEDDING_CACHE_PATH, "rb") as f:
                cached_data = pickle.load(f)
            if cached_data.get("formula_count") == len(_formulanames_raw):
                _embeddings = cached_data["embeddings"]
                logger.info(f"‚úÖ Loaded embeddings from cache ({_embeddings.shape})")
            else:
                logger.warning("‚ö†Ô∏è Embedding cache formula count mismatch, recalculating...")
                _embeddings = _compute_and_cache_embeddings()
        else:
            _embeddings = _compute_and_cache_embeddings()
    else:
        logger.warning("‚ö†Ô∏è sentence-transformers not installed ‚Äî semantic mode DISABLED.")
        _embedding_model = None
        _embeddings = None

    _initialized = True
    logger.info(f"‚úÖ ÂàùÂßãÂåñÂÆåÊàêÔºåÁî®Êó∂ {time.time() - start_time:.2f}s")


def _compute_and_cache_embeddings():
    """ÈáçÊñ∞ËÆ°ÁÆóÂπ∂ÁºìÂ≠òÂµåÂÖ•"""
    logger.info("üîÑ Computing new embeddings...")
    emb_list = _embedding_model.encode(
        _formulanames_raw, batch_size=64, show_progress_bar=True, convert_to_numpy=True
    )
    embeddings = l2_normalize_matrix(np.asarray(emb_list, dtype=np.float32))
    with open(EMBEDDING_CACHE_PATH, "wb") as f:
        pickle.dump({"formula_count": len(_formulanames_raw), "embeddings": embeddings}, f)
    logger.info(f"‚úÖ Cached new embeddings ({embeddings.shape})")
    return embeddings


# ===========================================================
# ÊêúÁ¥¢ÂáΩÊï∞ÔºàÊú™ÊîπÂä®Ôºâ
# ===========================================================
def fuzzy_search(user_input: str, topn: int = 5):
    key_clean = normalize_text(user_input)
    key_tokens = tokens_by_jieba(key_clean)
    if not key_tokens:
        return []

    results = process.extract(key_tokens, _formulanames_tokens, scorer=fuzz.token_set_ratio, limit=topn * 3)
    candidates = []
    for rank, (match_text, score, match_index) in enumerate(results, start=1):
        row = df.iloc[match_index]
        clean_name = str(row["FORMULANAME"]).strip().strip('"').strip("'")
        final_score = apply_text_weights(clean_name, float(score))
        candidates.append({
            "number": rank,
            "FORMULAID": row["FORMULAID"],
            "FORMULANAME": row["FORMULANAME"],
            "score": round(final_score, 4),
            "match_kind": "fuzzy_token_set"
        })
    return sorted(candidates, key=lambda x: x["score"], reverse=True)[:topn]


def semantic_search(user_input: str, topn: int = 5):
    model = _embedding_model
    if model is None:
        raise RuntimeError("Semantic model not available.")
    vec = model.encode([user_input], convert_to_numpy=True).astype(np.float32)
    vec = vec / (np.linalg.norm(vec, axis=1, keepdims=True) + 1e-12)
    sims = np.dot(_embeddings, vec[0])
    top_idx = np.argsort(-sims)[:topn * 3]
    candidates = []
    for rank, idx in enumerate(top_idx, start=1):
        row = df.iloc[int(idx)]
        clean_name = str(row["FORMULANAME"]).strip().strip('"').strip("'")
        base_score = float(sims[idx]) * 100.0
        final_score = apply_text_weights(clean_name, base_score)
        candidates.append({
            "number": rank,
            "FORMULAID": row["FORMULAID"],
            "FORMULANAME": clean_name,
            "score": round(final_score, 4),
            "match_kind": "semantic_cosine"
        })
    return sorted(candidates, key=lambda x: x["score"], reverse=True)[:topn]


def hybrid_search(user_input: str, topn: int = 5, fuzzy_weight: float = 0.4, semantic_weight: float = 0.6):
    fuzzy_candidates = fuzzy_search(user_input, topn=topn * 3)
    if not HAVE_ST or _embeddings is None:
        return fuzzy_candidates[:topn]

    model = _embedding_model
    vec = model.encode([user_input], convert_to_numpy=True).astype(np.float32)
    vec = vec / (np.linalg.norm(vec, axis=1, keepdims=True) + 1e-12)
    sims = np.dot(_embeddings, vec[0]) * 100.0

    merged = []
    for c in fuzzy_candidates:
        fid = c["FORMULAID"]
        matched_rows = df.index[df["FORMULAID"] == fid].tolist()
        if not matched_rows:
            continue
        idx = int(matched_rows[0])
        semantic_score = float(sims[idx])
        fuzzy_score = float(c["score"])
        if fuzzy_score > 95:
            fuzzy_weight, semantic_weight = 0.4, 0.6
        clean_name = str(df.iloc[idx]["FORMULANAME"]).strip().strip('"').strip("'")
        final_score = fuzzy_weight * fuzzy_score + semantic_weight * semantic_score
        final_score = apply_text_weights(clean_name, final_score)
        merged.append((final_score, fuzzy_score, semantic_score, idx))

    merged.sort(key=lambda x: x[0], reverse=True)
    candidates = []
    for rank, (final_score, fuzzy_score, semantic_score, idx) in enumerate(merged[:topn], start=1):
        row = df.iloc[idx]
        clean_name = str(row["FORMULANAME"]).strip().strip('"').strip("'")
        candidates.append({
            "number": rank,
            "FORMULAID": row["FORMULAID"],
            "FORMULANAME": clean_name,
            "score": round(float(final_score), 4),
            "fuzzy_score": round(float(fuzzy_score), 4),
            "semantic_score": round(float(semantic_score), 4),
            "match_kind": "hybrid"
        })
    return candidates


# ===========================================================
# API Êé•Âè£
# ===========================================================
@app.get("/formula_query")
def formula_query(
    user_input: str = Query(..., description="User input: keyword or exact formula name"),
    topn: int = Query(5, ge=1, le=50, description="Number of candidates to return"),
    method: str = Query("hybrid", description="Search method: fuzzy | semantic | hybrid")
):
    user_input = user_input.strip().strip('"').strip("'")
    if not user_input:
        return JSONResponse(content={"done": False, "message": "Empty input."})

    # Á≤æÁ°ÆÂåπÈÖç
    exact = df[df["FORMULANAME"] == user_input]
    if exact.empty:
        clean_input = normalize_text(user_input)
        matches_idx = [i for i, v in enumerate(_formulanames_clean) if v == clean_input]
        if matches_idx:
            exact = pd.DataFrame([df.iloc[matches_idx[0]]])
    if not exact.empty:
        exact_matches = exact[["FORMULAID", "FORMULANAME"]].to_dict(orient="records")
        for item in exact_matches:
            item["FORMULANAME"] = str(item["FORMULANAME"]).strip().strip('"').strip("'")
        return JSONResponse(content={
            "done": True,
            "message": f"Exact match found: {exact_matches[0]['FORMULANAME']}",
            "exact_matches": exact_matches
        })

    # Ê®°Á≥ä / ËØ≠‰πâ / Ê∑∑Âêà
    try:
        method = method.lower()
        if method == "fuzzy":
            candidates = fuzzy_search(user_input, topn=topn)
        elif method == "semantic":
            candidates = semantic_search(user_input, topn=topn)
        elif method == "hybrid":
            candidates = hybrid_search(user_input, topn=topn)
        else:
            return JSONResponse(content={"done": False, "message": f"Unknown method: {method}"})
    except Exception as e:
        logger.exception("‚ùå Search error")
        return JSONResponse(content={"done": False, "message": f"Search error: {e}", "candidates": []})

    if not candidates:
        return JSONResponse(content={"done": False, "message": "No matches found.", "candidates": []})

    msg_lines = ["Multiple candidates found, choose by number:"]
    for c in candidates:
        if c.get("match_kind") == "hybrid":
            msg_lines.append(f"{c['number']}) {c['FORMULANAME']} (final {c['score']}, fuzzy {c['fuzzy_score']}, semantic {c['semantic_score']})")
        else:
            msg_lines.append(f"{c['number']}) {c['FORMULANAME']} (score {c['score']})")

    return JSONResponse(content={
        "done": False,
        "message": "\n".join(msg_lines),
        "candidates": candidates
    })


@app.on_event("startup")
def load_csv_and_prepare():
    """FastAPI ÂêØÂä®Êó∂Ëá™Âä®Ë∞ÉÁî®"""
    initialize()


# ===========================================================
# Áã¨Á´ãËøêË°åÊîØÊåÅÔºàpython formula_api.pyÔºâ
# ===========================================================
if __name__ == "__main__":
    initialize()
    print("‚úÖ formula_api Áã¨Á´ãËøêË°åÊ®°ÂºèÂêØÂä®ÂÆåÊàê„ÄÇ")
